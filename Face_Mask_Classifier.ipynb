{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rETrWaAeu4iv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aokSHhLh4I4T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/hukkelas/DSFD-Pytorch-Inference.git\n",
      "  Cloning https://github.com/hukkelas/DSFD-Pytorch-Inference.git to /tmp/pip-req-build-vztyrjhw\n",
      "Requirement already satisfied (use --upgrade to upgrade): face-detection==0.2.1 from git+https://github.com/hukkelas/DSFD-Pytorch-Inference.git in /home/ace/anaconda3/lib/python3.8/site-packages/face_detection-0.2.1-py3.8.egg\n",
      "Requirement already satisfied: torch>=1.6 in /home/ace/.local/lib/python3.8/site-packages (from face-detection==0.2.1) (1.8.0)\n",
      "Requirement already satisfied: torchvision>=0.3.0 in /home/ace/.local/lib/python3.8/site-packages (from face-detection==0.2.1) (0.9.0)\n",
      "Requirement already satisfied: numpy in /home/ace/anaconda3/lib/python3.8/site-packages (from face-detection==0.2.1) (1.19.2)\n",
      "Requirement already satisfied: typing-extensions in /home/ace/.local/lib/python3.8/site-packages (from torch>=1.6->face-detection==0.2.1) (3.7.4.3)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/ace/anaconda3/lib/python3.8/site-packages (from torchvision>=0.3.0->face-detection==0.2.1) (8.0.1)\n",
      "Building wheels for collected packages: face-detection\n",
      "  Building wheel for face-detection (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for face-detection: filename=face_detection-0.2.1-py3-none-any.whl size=29721 sha256=8ce539945b90ca37971cff5409229f6b8710b9f4a7ea1a32ed10eb7f6ca97abb\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-6e03xl7k/wheels/57/d0/53/55657e0e64121cb64c10829c2f29bb3703afd0dcee55416e51\n",
      "Successfully built face-detection\n",
      "Requirement already satisfied: tqdm in /home/ace/.local/lib/python3.8/site-packages (4.59.0)\n"
     ]
    }
   ],
   "source": [
    "# Install Required Libraries from PyPI\n",
    "\n",
    "!pip install git+https://github.com/hukkelas/DSFD-Pytorch-Inference.git\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K4hzxFx9p0K_"
   },
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import face_detection\n",
    "from keras.applications import resnet50\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense,Dropout,AveragePooling2D,Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tqdm\n",
    "#from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WGwCQt_yPs5b"
   },
   "outputs": [],
   "source": [
    "# Initialize a Face Detector \n",
    "# Confidence Threshold can be Adjusted, Greater values would Detect only Clear Faces\n",
    "\n",
    "detector = face_detection.build_detector(\"DSFDDetector\", confidence_threshold=.5, nms_iou_threshold=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5HsIzcg5PDTm"
   },
   "source": [
    "## BLURRING AUGMENTATION ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Dmr3Z0kCZlL"
   },
   "outputs": [],
   "source": [
    "# Define Blurring Kernel Size Ranges, a Random Size would be chosen in the Specified Ranges\n",
    "# Greater the Size, Higher is the Blurring Effect (Adjustments can be made according to the needs)\n",
    "\n",
    "motion_blur_kernel_range = (4,8)  \n",
    "average_blur_kernel_range = (3,7)\n",
    "gaussian_blur_kernel_range = (3,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SuLM_nMaCZr6"
   },
   "outputs": [],
   "source": [
    "# Set Blurring Kernels to Use and their associated Probabilities\n",
    "\n",
    "Blurring_Kernels = [\"none\",\"motion\",\"gaussian\",\"average\"]\n",
    "Probs = [0.75,0.1,0.05,0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0fjXNQkcCmN7"
   },
   "outputs": [],
   "source": [
    "# Add Motion Blur to an Image in a Random Direction\n",
    "\n",
    "def motion_blur(img):\n",
    "\n",
    "  # Choose a Random Kernel Size\n",
    "  kernel_size = np.random.randint(motion_blur_kernel_range[0],motion_blur_kernel_range[1])\n",
    "  kernel = np.zeros((kernel_size, kernel_size))\n",
    "\n",
    "  # Random Selection of Direction of Motion Blur\n",
    "  types = [\"vertical\",\"horizontal\",\"main_diagonal\",\"anti_diagonal\"]\n",
    "  choice = np.random.choice(types)\n",
    "\n",
    "  if choice==\"vertical\":\n",
    "    kernel[:,int((kernel_size-1)/2)] = np.ones(kernel_size)/kernel_size\n",
    "  \n",
    "  elif choice==\"horizontal\":\n",
    "    kernel[int((kernel_size-1)/2),:] = np.ones(kernel_size)/kernel_size\n",
    "  \n",
    "  elif choice==\"main_diagonal\":\n",
    "    \n",
    "    for i in range(kernel_size):\n",
    "      kernel[i][i] = 1/kernel_size\n",
    "\n",
    "  elif choice==\"anti_diagonal\":\n",
    "\n",
    "    for i in range(kernel_size):\n",
    "      kernel[i][kernel_size-i-1] = 1/kernel_size\n",
    "\n",
    "  # Convolve and Return the Blurred Image\n",
    "  return cv2.filter2D(img,-1,kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1oV1z5DBCnHU"
   },
   "outputs": [],
   "source": [
    "# Add a Random Blur Effect to an Image with a Random Kernel Size (in the Specified Ranges)\n",
    "\n",
    "def get_blurred_picture(img):\n",
    "  \n",
    "  # Randomly choose a Blurring Technique\n",
    "  choice = np.random.choice(Blurring_Kernels,p=Probs)\n",
    "\n",
    "  # RGB to BGR for OpenCV\n",
    "  img = img[:,:,::-1]\n",
    "\n",
    "  if choice==\"none\":\n",
    "\n",
    "    random_blurred_img = img\n",
    "\n",
    "  elif choice==\"motion\":\n",
    "  \n",
    "    random_blurred_img  = motion_blur(img)\n",
    "\n",
    "  elif choice==\"gaussian\":\n",
    "\n",
    "    kernel_size = np.random.randint(gaussian_blur_kernel_range[0],gaussian_blur_kernel_range[1])\n",
    "\n",
    "    if kernel_size%2==0:\n",
    "      kernel_size-=1\n",
    "    \n",
    "    random_blurred_img = cv2.GaussianBlur(img,(kernel_size,kernel_size),0)\n",
    "\n",
    "  elif choice==\"average\":\n",
    "  \n",
    "    kernel_size = np.random.randint(average_blur_kernel_range[0],average_blur_kernel_range[1])\n",
    "    random_blurred_img = cv2.blur(img,(kernel_size,kernel_size))\n",
    "\n",
    "  # PreProcess for ResNet50\n",
    "  preprocessed = resnet50.preprocess_input(random_blurred_img[:,:,::-1])\n",
    "  \n",
    "  return preprocessed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iLSdHog6PHcO"
   },
   "source": [
    "## TRAINING ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WCJEPPGfqK29"
   },
   "outputs": [],
   "source": [
    "# Load Pretrained ResNet50 Model (without Last few Layers) \n",
    "# Freeze all the Layers\n",
    "\n",
    "base_network  = resnet50.ResNet50(input_shape = (224,224,3),weights='imagenet',include_top=False)\n",
    "for layer in base_network.layers:\n",
    "  layer.trainaibale = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wSwzjQedqQsr"
   },
   "outputs": [],
   "source": [
    "# Define the Face Mask Classifier Model by adding a few Layers on top of the ResNet50 Pretrained Model\n",
    "\n",
    "classifier_network = base_network.output\n",
    "classifier_network = AveragePooling2D(pool_size=(7, 7),name = \"Average_Pool_Final\")(classifier_network)\n",
    "classifier_network = Flatten(name = \"Flatten_Final\")(classifier_network)\n",
    "classifier_network = Dense(128, activation=\"relu\",name = \"Dense_Final\")(classifier_network)\n",
    "classifier_network = Dropout(0.5,name = \"Dropout_Final\")(classifier_network)\n",
    "classifier_network = Dense(1, activation=\"sigmoid\", name = \"Sigmoid_Classifier\" )(classifier_network)\n",
    "\n",
    "mask_classifier = Model(inputs=base_network.input, outputs=classifier_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uTalRyPrNk1w"
   },
   "outputs": [],
   "source": [
    "# Set Path to the Dataset\n",
    "# Faces would be extracted and placed in the specified Directory after Processing\n",
    "\n",
    "Dataset_PATH = \"./MainPath/Training_Data\"\n",
    "Processed_Dataset_PATH = \"./MainPath/Processed_Training_Data\"\n",
    "\n",
    "# Create Empty Directories\n",
    "os.mkdir(Processed_Dataset_PATH)\n",
    "os.mkdir(os.path.join(Processed_Dataset_PATH,\"with_mask\"))\n",
    "os.mkdir(os.path.join(Processed_Dataset_PATH,\"without_mask\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ZJlEg8y4Q_2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "259dd464740947f99655acbb5778bd98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare the Data for Training \n",
    "# Extract Faces from the Dataset and Save them in the specified Directory\n",
    "\n",
    "# There should be 2 Sub-Directories corresponding to Masked and Non-Masked Faces\n",
    "paths = [\"with_mask\",\"without_mask\"]\n",
    "\n",
    "for path in paths:\n",
    "\n",
    "  curr_path = os.path.join(Dataset_PATH,path)\n",
    "  \n",
    "  # Loop through all Images\n",
    "  for file_name in tqdm.notebook.tqdm(os.listdir(curr_path)):\n",
    "\n",
    "    try:\n",
    "      \n",
    "      image = cv2.imread(os.path.join(curr_path,file_name))\n",
    "\n",
    "      # Detect Faces, Crop and Save\n",
    "      detections = detector.detect(image[:,:,::-1])\n",
    "\n",
    "      for j in range(len(detections)):\n",
    "    \n",
    "        face = image[int(detections[j][1]):int(detections[j][3]),\n",
    "                     int(detections[j][0]):int(detections[j][2])]\n",
    "        \n",
    "        cv2.imwrite(os.path.join(Processed_Dataset_PATH,path)+\"/\"+file_name,face)\n",
    "    \n",
    "    except:\n",
    "      continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ezSSJGkwMrbo"
   },
   "outputs": [],
   "source": [
    "# Set the Hyper-Parameters\n",
    "\n",
    "alpha = 0.00001\n",
    "n_epochs = 5\n",
    "mini_batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x9SxYvmKNQMY"
   },
   "outputs": [],
   "source": [
    "# Compile the Model\n",
    "\n",
    "opt = Adam(learning_rate=alpha,decay = alpha/n_epochs)\n",
    "mask_classifier.compile(optimizer=opt,loss=\"binary_crossentropy\",metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UI9CuRrNJbcF"
   },
   "outputs": [],
   "source": [
    "# Define a ImageDataGenerator for Real-Time Data Augmentation\n",
    "# Parameters can be Tuned for controlling the Augmentation\n",
    "\n",
    "Data_Generator = ImageDataGenerator(horizontal_flip=True,\n",
    "                                    brightness_range=[0.5,1.25],\n",
    "                                    zoom_range=[0.8,1],\n",
    "                                    rotation_range = 15,\n",
    "                                    preprocessing_function=get_blurred_picture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jdHpqCnqKXQb"
   },
   "outputs": [],
   "source": [
    "# Create a Data_Generator Instance\n",
    "\n",
    "Train_Data_Generator = Data_Generator.flow_from_directory(Processed_Dataset_PATH,target_size=(224,224),\n",
    "                                                          class_mode=\"binary\",batch_size=mini_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OS6tgzXlLKgO"
   },
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "\n",
    "mask_classifier.fit(x=Train_Data_Generator,\n",
    "                    steps_per_epoch=(Train_Data_Generator.n//mini_batch_size),\n",
    "                    epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "colab_type": "code",
    "id": "QMVyxT5EeJR_",
    "outputId": "3459a26e-271f-4439-dfa8-2fe7a744fc49"
   },
   "outputs": [],
   "source": [
    "# Test the Model on a Picture\n",
    "\n",
    "FILE_PATH = \"drive/My Drive/Social_Distancing_with_AI/test.jpg\"\n",
    "\n",
    "img = cv2.imread(FILE_PATH)\n",
    "masked_faces = []\n",
    "unmasked_faces = []\n",
    "\n",
    "# Detect Faces\n",
    "detections = detector.detect(img[:,:,::-1])\n",
    "\n",
    "if detections.shape[0]>0:\n",
    "      \n",
    "  for i in range(detections.shape[0]):\n",
    "  \n",
    "    # Get Co-ordinates\n",
    "    x1 = int(detections[i][0])\n",
    "    x2 = int(detections[i][2])\n",
    "    y1 = int(detections[i][1])\n",
    "    y2 = int(detections[i][3])\n",
    "\n",
    "    # Predict Output\n",
    "    face_arr = cv2.resize(img[y1:y2,x1:x2,::-1], (224, 224), interpolation=cv2.INTER_NEAREST)\n",
    "    face_arr = np.expand_dims(face_arr, axis=0)\n",
    "    face_arr = resnet50.preprocess_input(face_arr)\n",
    "    match = mask_classifier.predict(face_arr)\n",
    "\n",
    "    if match[0][0]<0.5:\n",
    "      masked_faces.append([x1,y1,x2,y2])\n",
    "    else:\n",
    "      unmasked_faces.append([x1,y1,x2,y2])\n",
    "\n",
    "# Put Bounding Box on the Faces (Green:Masked,Red:Not-Masked)\n",
    "for f in range(len(masked_faces)):\n",
    "\n",
    "  a,b,c,d = masked_faces[f]\n",
    "  cv2.rectangle(img, (a,b), (c,d), (0,255,0), 2)\n",
    "\n",
    "for f in range(len(unmasked_faces)):\n",
    "\n",
    "  a,b,c,d = unmasked_faces[f]\n",
    "  cv2.rectangle(img, (a,b), (c,d), (0,0,255), 2)\n",
    "\n",
    "# Show Results\n",
    "cv2_imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wcZoAtsiMzDX"
   },
   "outputs": [],
   "source": [
    "# Save the Trained Weights to Disk\n",
    "\n",
    "SAVE_PATH = \"drive/My Drive/Social_Distancing_with_AI/ResNet50_Classifier.h5\"\n",
    "mask_classifier.save(SAVE_PATH)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Face_Mask_Classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
